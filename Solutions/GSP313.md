# GoogleCloudArchitectLabs


### GSP313 : Implement Load Balancing on Compute Engine: Challenge Lab (NEW METHOD)

### NOTE down all the values carefully (according to your LAB)

```bash
INSTANCE=nucleus-jumphost-502
FIREWALL=allow-tcp-rule-405
ZONE=us-east1-c
```

```bash
curl -LO https://raw.githubusercontent.com/tariqsheikhsw/GoogleCloudArchitectLabs/main/Solutions/GSP313-NEW.sh

sudo chmod +x GSP313-NEW.sh

./GSP313-NEW.sh
```

Lab Completed !!! 



### GSP313 : Implement Load Balancing on Compute Engine: Challenge Lab (VALID)

### Export all the values carefully (according to your LAB)

```bash
export INSTANCE=nucleus-jumphost-836
export FIREWALL=accept-tcp-rule-605
export ZONE=us-central1-c
```

```bash
curl -LO https://raw.githubusercontent.com/tariqsheikhsw/GoogleCloudArchitectLabs/main/Solutions/GSP313.sh

sudo chmod +x GSP313.sh

./GSP313.sh
```

Lab Completed !!! 



### OLD LAB (CHANGED)  - NOT VALID ANYMORE

```bash
export INSTANCE_NAME=nucleus-jumphost-836
export ZONE=us-central1-c
export PORT=8081  
export FIREWALL_NAME=accept-tcp-rule-605
```


###
###

### ***NOW JUST COPY THE CODE AND PASTE ON YOUR CLOUD SHELL***
###
###

//Lab is Updated : No Need to create cluster (nucleus-backend)
```bash 
curl -LO https://raw.githubusercontent.com/tariqsheikhsw/GoogleCloudArchitectLabs/main/Solutions/GSP313.sh
sudo chmod +x GSP313.sh
./GSP313.sh
```


### Details below (OPTIONAL)

- Challenge scenario

Task 1. Create a project jumphost instance

You will use this instance to perform maintenance for the project.

Requirements:

    - Name the instance .
    - Create the instance in the zone.
    - Use an e2-micro machine type.
    - Use the default image type (Debian Linux).


Task 2. Set up an HTTP load balancer

You will serve the site via nginx web servers, but you want to ensure that the environment is fault-tolerant. Create an HTTP load balancer with a managed instance group of 2 nginx web servers. Use the following code to configure the web servers; the team will replace this with their own configuration later.

```
cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF
```

Note: There is a limit to the resources you are allowed to create in your project, so do not create more than 2 instances in your managed instance group. If you do, the lab might end and you might be banned. 

You need to:

    - Create an instance template. Don't use the default machine type. Make sure you specify e2-medium as the machine type.
    - Create a managed instance group based on the template.
    - Create a firewall rule named as to allow traffic (80/tcp).
    - Create a health check.
    - Create a backend service and add your instance group as the backend to the backend service group with named port (http:80).
    - Create a URL map, and target the HTTP proxy to route the incoming requests to the default backend service.
    - Create a target HTTP proxy to route requests to your URL map
    - Create a forwarding rule.

Create startup.sh file

```
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF
```


```
export INSTANCE_NAME=nucleus-jumphost-794  
export ZONE=us-east1-c  
export PORT=8081  
export FIREWALL_NAME=accept-tcp-rule-607  
```


```
export REGION="${ZONE%-*}"
```

```
gcloud compute networks create nucleus-vpc --subnet-mode=auto

gcloud compute instances create $INSTANCE_NAME \
          --network nucleus-vpc \
          --zone $ZONE  \
          --machine-type e2-micro  \
          --image-family debian-10  \
          --image-project debian-cloud 

//OPTIONAL
gcloud container clusters create nucleus-backend \
--num-nodes 1 \
--network nucleus-vpc \
--zone $ZONE
 
//OPTIONAL
gcloud container clusters get-credentials nucleus-backend \
--zone $ZONE
 
//OPTIONAL 
kubectl create deployment hello-server \
--image=gcr.io/google-samples/hello-app:2.0

//OPTIONAL  
kubectl expose deployment hello-server \
--type=LoadBalancer \
--port $PORT
 
  
cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

 
gcloud compute instance-templates create web-server-template \
--metadata-from-file startup-script=startup.sh \
--network nucleus-vpc \
--machine-type e2-medium \
--region $ZONE
 
 
gcloud compute target-pools create nginx-pool --region=$REGION
 
 
gcloud compute instance-groups managed create web-server-group \
--base-instance-name web-server \
--size 2 \
--template web-server-template \
--region $REGION
 
 
gcloud compute firewall-rules create $FIREWALL_NAME \
--allow tcp:80 \
--network nucleus-vpc
 
 
gcloud compute http-health-checks create http-basic-check
gcloud compute instance-groups managed \
set-named-ports web-server-group \
--named-ports http:80 \
--region $REGION
 
 
gcloud compute backend-services create web-server-backend \
--protocol HTTP \
--http-health-checks http-basic-check \
--global
 
 
gcloud compute backend-services add-backend web-server-backend \
--instance-group web-server-group \
--instance-group-region $REGION \
--global
 
 
gcloud compute url-maps create web-server-map \
--default-service web-server-backend
 
 
gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-server-map
 
 
 
gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80
 
 
gcloud compute forwarding-rules create $FIREWALL_NAME \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list
```









